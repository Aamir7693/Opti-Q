{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4igAZs1pCiK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "metrics_updated.py — compute Total_Cost / Total_Energy / Total_Latency\n",
        "from step_logs using split input/output coefficients and blend-by-type.\n",
        "\n",
        "Assignment mapping:\n",
        "    0: mistral, 1: llama, 2: phi, 3: qwen, 4: gemma, 5: blend\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import logging\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, Any, Tuple, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "# Logging\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s • %(levelname)s • %(message)s\"\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "# Rate tables (example: for query_type = \"Art\"), keyed by assignment id\n",
        "# 0: mistral, 1: llama, 2: phi, 3: qwen, 4: gemma, 5: blend\n",
        "# Values are per token.\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "ART_SPECS: Dict[int, Dict[str, float]] = {\n",
        "    0: {\"input_cost\": 2.8e-08,  \"output_cost\": 5.4e-08,  \"input_latency\": 0.159983, \"output_latency\": 0.159983, \"input_energy\": 0.103939, \"output_energy\": 0.103939},  # mistral\n",
        "    1: {\"input_cost\": 5.5e-08,  \"output_cost\": 5.5e-08,  \"input_latency\": 0.15,     \"output_latency\": 0.15,     \"input_energy\": 0.10552,  \"output_energy\": 0.10552},   # llama\n",
        "    2: {\"input_cost\": 6e-08,\"output_cost\": 1.4e-07,  \"input_latency\": 0.133333, \"output_latency\": 0.133333, \"input_energy\": 0.1,      \"output_energy\": 0.1},       # phi\n",
        "    3: {\"input_cost\": 6e-08,\"output_cost\": 2.4e-07,\"input_latency\": 0.095852, \"output_latency\": 0.095852, \"input_energy\": 0.066938, \"output_energy\": 0.066938},  # qwen\n",
        "    4: {\"input_cost\": 9e-08,\"output_cost\": 1.6e-07,\"input_latency\": 0.059915, \"output_latency\": 0.059915, \"input_energy\": 0.083433, \"output_energy\": 0.083433},  # gemma\n",
        "    5: {\"input_cost\": 9e-08,\"output_cost\": 1.6e-07,\"input_latency\": 0.059915, \"output_latency\": 0.059915, \"input_energy\": 0.083433, \"output_energy\": 0.083433},  # blend\n",
        "}\n",
        "\n",
        "def get_rate_table(query_type: str) -> Dict[int, Dict[str, float]]:\n",
        "    \"\"\"\n",
        "    Return the per-assignment rate table for a given query_type.\n",
        "    Extend this to switch on query_type if you have multiple tables.\n",
        "    \"\"\"\n",
        "    # For now, we return the ART table for everything; customize as needed.\n",
        "    return ART_SPECS\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "# Assignment mapping (model/type → assignment id)\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "def model_to_assignment(model: str, step_type: str) -> int:\n",
        "    \"\"\"\n",
        "    Map a step's (model, type) to an assignment id.\n",
        "    Uses 'blend' step_type to identify the blend node.\n",
        "    \"\"\"\n",
        "    t = (step_type or \"\").lower().strip()\n",
        "    m = (model or \"\").lower().strip()\n",
        "    if t == \"blend\":\n",
        "        return 5\n",
        "    if m.startswith(\"mistral\"):\n",
        "        return 0\n",
        "    if m.startswith(\"llama\"):\n",
        "        return 1\n",
        "    if m.startswith(\"phi\"):\n",
        "        return 2\n",
        "    if m.startswith(\"qwen\"):\n",
        "        return 3\n",
        "    if m.startswith(\"gemma\"):\n",
        "        return 4\n",
        "    # Fallback: treat as gemma-like\n",
        "    return 4\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "# Adjacency builder (struct_id bitmask → DAG adjacency)\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "_adj_cache: Dict[Tuple[int, int], np.ndarray] = {}\n",
        "\n",
        "def build_adjacency(mask: int, k: int) -> np.ndarray:\n",
        "    \"\"\"Build adjacency matrix from struct_id mask for k nodes, cached for speed.\"\"\"\n",
        "    key = (mask, k)\n",
        "    if key in _adj_cache:\n",
        "        return _adj_cache[key]\n",
        "    B = [(mask >> bit) & 1 for bit in range(k*(k-1)//2)]\n",
        "    adj = np.zeros((k, k), dtype=int)\n",
        "    idx = 0\n",
        "    for i in range(k-1):\n",
        "        for j in range(i+1, k):\n",
        "            adj[i, j] = B[idx]\n",
        "            idx += 1\n",
        "    _adj_cache[key] = adj\n",
        "    return adj\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "# Core computation: single pass; split pricing; blend-by-type; longest-path latency\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "def compute_totals_from_step_logs(step_logs_json: str, struct_id: str,\n",
        "                                  rate_table: Dict[int, Dict[str,float]]) -> Tuple[float,float,float]:\n",
        "    \"\"\"\n",
        "    Given a JSON list of step logs and a struct_id mask, compute:\n",
        "        Total_Cost, Total_Energy, Total_Latency\n",
        "    using split input/output pricing and longest-path latency aggregation.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        steps: List[Dict[str, Any]] = sorted(json.loads(step_logs_json or \"[]\"),\n",
        "                                             key=lambda x: x.get(\"node\", 0))\n",
        "    except json.JSONDecodeError:\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    k = len(steps)\n",
        "    mask_str = str(struct_id).strip(\"()\")\n",
        "    mask = int(mask_str.split(\",\")[0]) if mask_str else 0\n",
        "    adj = build_adjacency(mask, k)\n",
        "\n",
        "    total_cost = 0.0\n",
        "    total_energy = 0.0\n",
        "    node_latency = [0.0] * k\n",
        "\n",
        "    for st in steps:\n",
        "        a = model_to_assignment(st.get(\"model\",\"\"), st.get(\"type\",\"\"))\n",
        "        rt = rate_table[a]\n",
        "        Tin  = float(st.get(\"input_tokens\", 0))\n",
        "        Tout = float(st.get(\"output_tokens\", 0))\n",
        "        idx  = int(st.get(\"node\", 0))\n",
        "\n",
        "        total_cost   += Tin*rt[\"input_cost\"]    + Tout*rt[\"output_cost\"]\n",
        "        total_energy += Tin*rt[\"input_energy\"]  + Tout*rt[\"output_energy\"]\n",
        "        node_latency[idx] = Tin*rt[\"input_latency\"] + Tout*rt[\"output_latency\"]\n",
        "\n",
        "    # longest-path latency on DAG defined by mask\n",
        "    if k == 0:\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    longest = node_latency.copy()\n",
        "    for i in range(k):\n",
        "        for j in range(i+1, k):\n",
        "            if adj[i, j]:\n",
        "                # If edge i->j exists, update the best arrival time at j\n",
        "                longest[j] = max(longest[j], longest[i] + node_latency[j])\n",
        "\n",
        "    return total_cost, total_energy, max(longest)\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "# DataFrame helper\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "def add_totals(df: pd.DataFrame, query_type_col: str = \"query_type\") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute Total_Cost / Total_Energy / Total_Latency for each row in df,\n",
        "    reading per-step tokens from 'step_logs' and the DAG from 'struct_id'.\n",
        "    \"\"\"\n",
        "    out = df.copy()\n",
        "    totals: List[Tuple[float,float,float]] = []\n",
        "    for _, r in out.iterrows():\n",
        "        rate_table = get_rate_table(str(r.get(query_type_col, \"Art\")))\n",
        "        c, e, l = compute_totals_from_step_logs(\n",
        "            r.get(\"step_logs\", \"[]\"),\n",
        "            str(r.get(\"struct_id\", \"0\")),\n",
        "            rate_table\n",
        "        )\n",
        "        totals.append((c, e, l))\n",
        "    out[[\"Total_Cost\", \"Total_Energy\", \"Total_Latency\"]] = pd.DataFrame(totals, index=out.index)\n",
        "    return out\n",
        "\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "# CLI\n",
        "# ────────────────────────────────────────────────────────────────────────────────\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Compute totals from step logs with split input/output pricing.\")\n",
        "    parser.add_argument(\"--input\", required=True, help=\"Input CSV (must contain 'step_logs' and 'struct_id').\")\n",
        "    parser.add_argument(\"--output\", required=True, help=\"Output CSV path.\")\n",
        "    parser.add_argument(\"--query_type_col\", default=\"query_type\", help=\"Column name for query type (default: query_type).\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    df = pd.read_csv(args.input)\n",
        "    df2 = add_totals(df, args.query_type_col)\n",
        "    df2.to_csv(args.output, index=False)\n",
        "    logger.info(f\"Wrote {args.output}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}